{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd08940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import random\n",
    "import pyrubberband as pyrb\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b79ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_audio_and_transcript(input_audio_path, transcript_path, \n",
    "                               output_audio_path, output_transcript_path,\n",
    "                               buffer_sec=0.1, min_gap_for_pause=2.0, \n",
    "                               pause_duration=0.5):\n",
    "    \"\"\"\n",
    "    Clean audio and transcript by extracting only participant segments\n",
    "    \n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------ I/O\n",
    "    audio, sr = sf.read(input_audio_path)\n",
    "    if audio.ndim > 1:\n",
    "        audio = librosa.to_mono(audio)               \n",
    "    transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "\n",
    "    # ---------- 1) porta l'asse dei tempi a 0 prima di qualunque elaborazione\n",
    "    ### MOD: calcolo offset\n",
    "    offset = transcript['start_time'].min()\n",
    "    transcript['start_time'] -= offset\n",
    "    transcript['stop_time']  -= offset\n",
    "    transcript['start_time']= transcript['start_time'].clip(lower=0)             \n",
    "    transcript['stop_time']= transcript['stop_time'].clip(lower=0) \n",
    "    # ---------- 2) filtra solo i segmenti del Participant (stessa tua logica)\n",
    "    participant_segments = transcript[\n",
    "        (transcript['speaker'] == 'Participant') &\n",
    "        (~transcript['value'].str.contains('scrubbed_entry|<synch>|<sync>', \n",
    "                                           na=False))\n",
    "    ].copy()\n",
    "\n",
    "    # ---------- 3) indici in campioni, buffer\n",
    "    buffer_samples = int(buffer_sec * sr)\n",
    "    starts = ((participant_segments['start_time'] * sr).astype(np.int32)\n",
    "              - buffer_samples).clip(lower=0)\n",
    "    ends   = ((participant_segments['stop_time']  * sr).astype(np.int32)\n",
    "              + buffer_samples).clip(upper=len(audio))\n",
    "\n",
    "    # ---------- 4) pause tra segmenti (tua logica invariata)\n",
    "    insert_pause = []\n",
    "    for i in range(len(participant_segments) - 1):\n",
    "        current_end = participant_segments.iloc[i]['stop_time']\n",
    "        next_start  = participant_segments.iloc[i + 1]['start_time']\n",
    "        gap_duration = next_start - current_end\n",
    "        insert_pause.append(gap_duration >= min_gap_for_pause)\n",
    "\n",
    "    # ---------- 5) estrai audio + eventuali pause\n",
    "    audio_segments = []\n",
    "    pause_samples = np.zeros(int(pause_duration * sr), dtype=np.float32)\n",
    "\n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        audio_segments.append(audio[s:e])\n",
    "\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            audio_segments.append(pause_samples)\n",
    "\n",
    "    # gestisci caso senza segmenti validi\n",
    "    if not audio_segments:\n",
    "        raise ValueError(\"Nessun segmento 'Participant' nel transcript\")\n",
    "\n",
    "    cleaned_audio = np.concatenate(audio_segments)\n",
    "\n",
    "    # ---------- 6) ricostruisci timestamp output\n",
    "    current_time = 0.0\n",
    "    new_starts, new_stops = [], []\n",
    "\n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        segment_duration = (e - s) / sr\n",
    "        new_starts.append(current_time)\n",
    "        current_time += segment_duration\n",
    "        new_stops.append(current_time)\n",
    "\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            current_time += pause_duration\n",
    "\n",
    "    participant_segments['start_time'] = new_starts\n",
    "    participant_segments['stop_time']  = new_stops\n",
    "    participant_segments = participant_segments.drop('speaker', axis=1)\n",
    "\n",
    "    # ---------- 7) salva e ritorna\n",
    "    sf.write(output_audio_path, cleaned_audio, sr, subtype='PCM_16')\n",
    "    participant_segments.to_csv(output_transcript_path, sep='\\t', index=False)\n",
    "\n",
    "    original_duration = len(audio) / sr\n",
    "    cleaned_duration  = len(cleaned_audio) / sr\n",
    "    return original_duration, cleaned_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd88443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../datasets/DAIC-WOZ -> ../datasets/DAIC-WOZ-preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DAIC-WOZ sessions: 100%|██████████| 189/189 [00:15<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ../datasets/EDAIC-WOZ -> ../datasets/EDAIC-WOZ-preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing EDAIC-WOZ sessions: 100%|██████████| 29/29 [00:10<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Elaborazione dataset - salva in directory separate\n",
    "dataset_configs = [\n",
    "    {\"input_dir\": \"../datasets/DAIC-WOZ\", \"output_dir\": \"../datasets/DAIC-WOZ-preprocessed\"},\n",
    "    {\"input_dir\": \"../datasets/EDAIC-WOZ\", \"output_dir\": \"../datasets/EDAIC-WOZ-preprocessed\"}\n",
    "]\n",
    "\n",
    "for config in dataset_configs:\n",
    "    dataset_dir = config[\"input_dir\"]\n",
    "    output_dir = config[\"output_dir\"]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    dataset_sessions = sorted([d for d in os.listdir(dataset_dir) \\\n",
    "                   if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "\n",
    "    print(f\"Processing {dataset_dir} -> {output_dir}\")\n",
    "    for session in tqdm(dataset_sessions, desc=f\"Processing {os.path.basename(dataset_dir)} sessions\"):\n",
    "        session_path = os.path.join(dataset_dir, session)\n",
    "        session_id = session.replace(\"_P\", \"\")\n",
    "\n",
    "        # Percorsi file input\n",
    "        audio_path = os.path.join(session_path, f\"{session_id}_AUDIO.wav\")\n",
    "        transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        # Percorsi file output\n",
    "        output_session_path = os.path.join(output_dir, session)\n",
    "        os.makedirs(output_session_path, exist_ok=True)\n",
    "        output_audio_path = os.path.join(output_session_path, f\"{session_id}_AUDIO.wav\")\n",
    "        output_transcript_path = os.path.join(output_session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        # Processa sessione\n",
    "        original_duration, cleaned_duration = clean_audio_and_transcript(\n",
    "            audio_path, transcript_path, output_audio_path, output_transcript_path, \n",
    "            buffer_sec=0.1, min_gap_for_pause=2.0, pause_duration=0.5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "171567b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_lengths(dataset_dir):\n",
    "    \"\"\"\n",
    "    Analizza le lunghezze degli audio per determinare parametri ottimali\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistiche delle durate\n",
    "    \"\"\"\n",
    "    print(\"Analizzando lunghezze audio...\")\n",
    "    durations = []\n",
    "    session_names = []\n",
    "    session_dirs = sorted([d for d in os.listdir(dataset_dir) \\\n",
    "                   if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "\n",
    "    for session in tqdm(session_dirs, desc=\"Analisi campione\"):\n",
    "        session_path = os.path.join(dataset_dir, session)\n",
    "        session_id = session.replace(\"_P\", \"\")\n",
    "        transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "        durations.append(transcript['stop_time'].max())\n",
    "        session_names.append(session_id) \n",
    "    \n",
    "    durations = np.array(durations)\n",
    "    min_idx = np.argmin(durations)\n",
    "    max_idx = np.argmax(durations)\n",
    "    \n",
    "    stats = {\n",
    "        'count': len(durations),\n",
    "        'mean': np.mean(durations),\n",
    "        'median': np.median(durations),\n",
    "        'std': np.std(durations),\n",
    "        'min': np.min(durations),\n",
    "        'max': np.max(durations),\n",
    "        'min_audio': session_names[min_idx],  # Nome audio con durata minima\n",
    "        'max_audio': session_names[max_idx],  # Nome audio con durata massima\n",
    "        'q25': np.percentile(durations, 25),\n",
    "        'q75': np.percentile(durations, 75)\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca86e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pitch_shift(audio, sr):\n",
    "    \"\"\"\n",
    "    Pitch-shift di alta qualità (-1.5 semitoni di default) SOLO con Rubber Band.\n",
    "    \n",
    "    • Input:  audio mono (np.ndarray), sr originale\n",
    "    • Output: audio shiftato (float32), sr invariato\n",
    "    \"\"\"\n",
    "    n_steps = -1.5  # Pitch shift di -1.5 semitono\n",
    "    # 1) garantisci float32\n",
    "    tmp_sr=48_000\n",
    "    # 2) upsample provvisorio se l’originale è sotto tmp_sr (es. 16 kHz → 48 kHz)\n",
    "    if sr < tmp_sr:\n",
    "        audio_up = librosa.resample(y=audio, orig_sr=sr,target_sr=tmp_sr)\n",
    "        sr_up = tmp_sr\n",
    "    else:\n",
    "        audio_up, sr_up = audio, sr\n",
    "\n",
    "    # 3) Rubber Band – motore R3 + preserva formanti\n",
    "    shifted = pyrb.pitch_shift(\n",
    "        audio_up,\n",
    "        sr_up,\n",
    "        n_steps,\n",
    "        rbargs={\"-3\": \"\", \"-F\": \"\"}     # R3 fine engine + formant preserving\n",
    "    )\n",
    "\n",
    "    # 4) ridownsample allo sr originale se l’avevi alzato\n",
    "    if sr_up != sr:\n",
    "        shifted = librosa.resample(shifted, sr_up, sr, res_type=\"soxr_vhq\")\n",
    "\n",
    "    # 5) normalizza per evitare clip quando scrivi in PCM-16\n",
    "    peak = np.max(np.abs(shifted))\n",
    "    if peak > 1e-5:\n",
    "        shifted /= peak * 1.001        # ~-0.01 dB di margine\n",
    "\n",
    "    return shifted.astype(np.float32)\n",
    "\n",
    "def create_tone_change_augmentation(dataset_dirs, labels_dict, dataset_csv_path, percentage=0.2, pitch_steps=2):\n",
    "    \"\"\"\n",
    "    Crea augmentation con tone change per i campioni di classe 1\n",
    "    \n",
    "    Args:\n",
    "        dataset_dirs: Lista delle directory dei dataset preprocessati\n",
    "        labels_dict: Dizionario con le etichette {session_id: label}\n",
    "        dataset_csv_path: Path del file dataset.csv da aggiornare\n",
    "        percentage: Percentuale di campioni da modificare\n",
    "        pitch_steps: Numero di semitoni per il pitch shift\n",
    "    \n",
    "    Returns:\n",
    "        Lista delle nuove entry create\n",
    "    \"\"\"\n",
    "    print(f\"Creando augmentation con tone change per il {percentage*100}% dei campioni di classe 1...\")\n",
    "    \n",
    "    # Carica il dataset CSV esistente\n",
    "    dataset_df = pd.read_csv(dataset_csv_path)\n",
    "    new_entries = []\n",
    "    \n",
    "    for dataset_dir in dataset_dirs:\n",
    "        print(f\"Processando {dataset_dir}...\")\n",
    "        \n",
    "        # Trova tutti i campioni di classe 1 nel dataset\n",
    "        class1_sessions = []\n",
    "        session_dirs = sorted([d for d in os.listdir(dataset_dir) \n",
    "                              if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "        \n",
    "        for session in session_dirs:\n",
    "            session_id = session.replace('_P', '')\n",
    "            if labels_dict.get(session_id, 0) == 1:  # Classe 1 (depresso)\n",
    "                class1_sessions.append(session)\n",
    "        \n",
    "        print(f\"Trovati {len(class1_sessions)} campioni di classe 1 in {os.path.basename(dataset_dir)}\")\n",
    "        \n",
    "        if len(class1_sessions) == 0:\n",
    "            print(f\"Nessun campione di classe 1 trovato in {dataset_dir}\")\n",
    "            continue\n",
    "            \n",
    "        # Seleziona casualmente la percentuale specificata dei campioni di classe 1\n",
    "        num_to_modify = int(len(class1_sessions) * percentage)\n",
    "        if num_to_modify == 0:\n",
    "            print(f\"Nessun campione da modificare in {dataset_dir}\")\n",
    "            continue\n",
    "            \n",
    "        sessions_to_modify = random.sample(class1_sessions, num_to_modify)\n",
    "        \n",
    "        print(f\"Creando {num_to_modify} nuovi campioni ({percentage*100}%) in {os.path.basename(dataset_dir)}\")\n",
    "        \n",
    "        # Crea tone change per i campioni selezionati\n",
    "        for session in tqdm(sessions_to_modify, desc=f\"Tone change {os.path.basename(dataset_dir)}\"):\n",
    "            session_path = os.path.join(dataset_dir, session)\n",
    "            session_id = session.replace('_P', '')\n",
    "            \n",
    "            # File originali\n",
    "            original_audio_path = os.path.join(session_path, f\"{session_id}_AUDIO.wav\")\n",
    "            original_transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "            \n",
    "            # Nuovi nomi per i file augmentati\n",
    "            new_session_id = f\"{session_id}_tone\"\n",
    "            new_session_dir = f\"{session_id}_tone_P\"\n",
    "            \n",
    "            # Crea directory per il nuovo campione\n",
    "            new_session_path = os.path.join(dataset_dir, new_session_dir)\n",
    "            os.makedirs(new_session_path, exist_ok=True)\n",
    "            \n",
    "            # Percorsi per i nuovi file\n",
    "            new_audio_path = os.path.join(new_session_path, f\"{new_session_id}_AUDIO.wav\")\n",
    "            new_transcript_path = os.path.join(new_session_path, f\"{new_session_id}_TRANSCRIPT.csv\")\n",
    "            \n",
    "            # Leggi e modifica audio\n",
    "            audio, sr = sf.read(original_audio_path)\n",
    "            \n",
    "            modified_audio = apply_pitch_shift(audio, sr)\n",
    "            \n",
    "            # Salva nuovo audio\n",
    "            sf.write(new_audio_path, modified_audio, sr, subtype='PCM_16')\n",
    "            \n",
    "            # Copia il transcript (uguale all'originale)\n",
    "            original_transcript = pd.read_csv(original_transcript_path, sep='\\t')\n",
    "            original_transcript.to_csv(new_transcript_path, sep='\\t', index=False)\n",
    "            \n",
    "            # Crea entry per il dataset.csv\n",
    "            dataset_df['Participant_ID'] = dataset_df['Participant_ID'].astype(str)\n",
    "            original_entry = dataset_df[dataset_df['Participant_ID'] == session_id].iloc[0]\n",
    "            new_entry = {\n",
    "                'session_id': new_session_id,\n",
    "                'label': original_entry['PHQ_Binary'],  # Mantiene la stessa etichetta\n",
    "                'augmentation': 'tone_change'  # Aggiungi colonna per indicare l'augmentation\n",
    "            }\n",
    "            \n",
    "            # Aggiungi altre colonne se presenti nel dataset originale\n",
    "            for col in dataset_df.columns:\n",
    "                if col not in new_entry:\n",
    "                    new_entry[col] = original_entry[col]\n",
    "            \n",
    "            new_entries.append(new_entry)\n",
    "            \n",
    "        print(f\"Tone change completato per {len(sessions_to_modify)} campioni in {os.path.basename(dataset_dir)}\")\n",
    "    \n",
    "    # Aggiungi le nuove entry al dataset\n",
    "    if new_entries:\n",
    "        new_df = pd.DataFrame(new_entries)\n",
    "        \n",
    "        # Aggiungi colonna augmentation se non esiste\n",
    "        if 'augmentation' not in dataset_df.columns:\n",
    "            dataset_df['augmentation'] = 'none'\n",
    "            \n",
    "        # Concatena i nuovi dati\n",
    "        updated_dataset_df = pd.concat([dataset_df, new_df], ignore_index=True)\n",
    "        \n",
    "        # Salva il dataset aggiornato\n",
    "        updated_dataset_df.to_csv(dataset_csv_path, index=False)\n",
    "        print(f\"Dataset aggiornato con {len(new_entries)} nuove entry salvato in {dataset_csv_path}\")\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37492351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuale per tone change: 20.0%\n",
      "Numero totale di sessioni: 218\n",
      "Sessioni di classe 1: 86\n",
      "Creando augmentation con tone change per il 20.0% dei campioni di classe 1...\n",
      "Processando ../datasets/DAIC-WOZ-preprocessed...\n",
      "Trovati 57 campioni di classe 1 in DAIC-WOZ-preprocessed\n",
      "Creando 11 nuovi campioni (20.0%) in DAIC-WOZ-preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tone change DAIC-WOZ-preprocessed:   0%|          | 0/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to execute rubberband. Please verify that rubberband-cli is installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\site-packages\\pyrubberband\\pyrb.py:70\u001b[0m, in \u001b[0;36m__rubberband\u001b[1;34m(y, sr, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m arguments\u001b[38;5;241m.\u001b[39mextend([infile, outfile])\n\u001b[1;32m---> 70\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Load the processed audio.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03mthe exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03mCalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03mcheck_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m retcode \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode:\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\subprocess.py:345\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03mtimeout, then return the returncode attribute.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03mretcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\subprocess.py:1456\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1456\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1457\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1458\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Impossibile trovare il file specificato",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m preprocessed_dirs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/DAIC-WOZ-preprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/EDAIC-WOZ-preprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Crea augmentation con tone change\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m new_entries \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_tone_change_augmentation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessed_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpercentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpercentage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpitch_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreati \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_entries)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nuovi campioni con tone change\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m new_entries[:\u001b[38;5;241m5\u001b[39m]:  \u001b[38;5;66;03m# Mostra i primi 5 per verifica\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 110\u001b[0m, in \u001b[0;36mcreate_tone_change_augmentation\u001b[1;34m(dataset_dirs, labels_dict, dataset_csv_path, percentage, pitch_steps)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Leggi e modifica audio\u001b[39;00m\n\u001b[0;32m    108\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mread(original_audio_path)\n\u001b[1;32m--> 110\u001b[0m modified_audio \u001b[38;5;241m=\u001b[39m \u001b[43mapply_pitch_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Salva nuovo audio\u001b[39;00m\n\u001b[0;32m    113\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(new_audio_path, modified_audio, sr, subtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCM_16\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mapply_pitch_shift\u001b[1;34m(audio, sr)\u001b[0m\n\u001b[0;32m     16\u001b[0m     audio_up, sr_up \u001b[38;5;241m=\u001b[39m audio, sr\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 3) Rubber Band – motore R3 + preserva formanti\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m shifted \u001b[38;5;241m=\u001b[39m \u001b[43mpyrb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpitch_shift\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_up\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr_up\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrbargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-F\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# R3 fine engine + formant preserving\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 4) ridownsample allo sr originale se l’avevi alzato\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr_up \u001b[38;5;241m!=\u001b[39m sr:\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\site-packages\\pyrubberband\\pyrb.py:258\u001b[0m, in \u001b[0;36mpitch_shift\u001b[1;34m(y, sr, n_steps, rbargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     rbargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    256\u001b[0m rbargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--pitch\u001b[39m\u001b[38;5;124m'\u001b[39m, n_steps)\n\u001b[1;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m __rubberband(y, sr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrbargs)\n",
      "File \u001b[1;32mc:\\Users\\anto-\\Miniconda3\\envs\\speech_project\\lib\\site-packages\\pyrubberband\\pyrb.py:80\u001b[0m, in \u001b[0;36m__rubberband\u001b[1;34m(y, sr, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m         y_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(y_out)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to execute rubberband. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease verify that rubberband-cli \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     82\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis installed.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# Remove temp files\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(infile)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to execute rubberband. Please verify that rubberband-cli is installed."
     ]
    }
   ],
   "source": [
    "# Carica il dataset CSV per ottenere le etichette e la percentuale\n",
    "dataset_csv_path = \"../datasets/dataset.csv\"\n",
    "dataset_df = pd.read_csv(dataset_csv_path)\n",
    "# Crea dizionario delle etichette\n",
    "labels_dict = dict(zip(dataset_df['Participant_ID'].astype(str), dataset_df['PHQ_Binary']))\n",
    "\n",
    "# Leggi la percentuale dal CSV (assumendo che ci sia una colonna 'tone_change_percentage')\n",
    "# Se non esiste, usa un valore di default\n",
    "if 'tone_change_percentage' in dataset_df.columns:\n",
    "    # Prendi il primo valore non-null della colonna percentuale\n",
    "    percentage = dataset_df['tone_change_percentage'].dropna().iloc[0] if not dataset_df['tone_change_percentage'].dropna().empty else 0.2\n",
    "else:\n",
    "    percentage = 0.2  # Default 20%\n",
    "\n",
    "print(f\"Percentuale per tone change: {percentage*100}%\")\n",
    "print(f\"Numero totale di sessioni: {len(labels_dict)}\")\n",
    "print(f\"Sessioni di classe 1: {sum(1 for v in labels_dict.values() if v == 1)}\")\n",
    "\n",
    "# Directory dei dataset preprocessati\n",
    "preprocessed_dirs = [\"../datasets/DAIC-WOZ-preprocessed\", \"../datasets/EDAIC-WOZ-preprocessed\"]\n",
    "\n",
    "# Crea augmentation con tone change\n",
    "new_entries = create_tone_change_augmentation(\n",
    "    preprocessed_dirs, \n",
    "    labels_dict, \n",
    "    dataset_csv_path, \n",
    "    percentage=percentage, \n",
    "    pitch_steps=0\n",
    ")\n",
    "\n",
    "print(f\"Creati {len(new_entries)} nuovi campioni con tone change\")\n",
    "for entry in new_entries[:5]:  # Mostra i primi 5 per verifica\n",
    "    print(f\"- {entry['Participant_ID']} , label: {entry['PHQ_Binary']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
