{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd08940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_audio_and_transcript(input_audio_path, transcript_path, output_audio_path, output_transcript_path,\n",
    "                               buffer_sec=0.1, min_gap_for_pause=2.0, pause_duration=0.5):\n",
    "    \"\"\"\n",
    "    Clean audio and transcript by extracting only participant segments\n",
    "    \n",
    "    Args:\n",
    "        input_audio_path: Path to input audio file\n",
    "        transcript_path: Path to input transcript CSV\n",
    "        output_audio_path: Path for cleaned audio output\n",
    "        output_transcript_path: Path for cleaned transcript output\n",
    "        buffer_sec: Buffer time in seconds to add around segments\n",
    "        min_gap_for_pause: Minimum gap between segments to insert a pause (seconds)\n",
    "        pause_duration: Duration of inserted pause (seconds)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original_duration, cleaned_duration)\n",
    "    \"\"\"\n",
    "    # Lettura file\n",
    "    audio, sr = sf.read(input_audio_path)\n",
    "    transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "\n",
    "    # Filtra solo segmenti partecipante\n",
    "    participant_segments = transcript[\n",
    "        (transcript['speaker'] == 'Participant') &\n",
    "        (~transcript['value'].str.contains('scrubbed_entry|<synch>|<sync>', na=False))\n",
    "    ].copy()\n",
    "    \n",
    "    # Calcola posizioni in samples e aggiungi buffer\n",
    "    buffer_samples = int(buffer_sec * sr)\n",
    "    starts = ((participant_segments['start_time'] * sr).astype(np.int32) - buffer_samples).clip(lower=0)\n",
    "    ends = ((participant_segments['stop_time'] * sr).astype(np.int32) + buffer_samples).clip(upper=len(audio))\n",
    "\n",
    "    # Controlla gap tra segmenti consecutivi del partecipante\n",
    "    insert_pause = []\n",
    "    for i in range(len(participant_segments) - 1):\n",
    "        current_end = participant_segments.iloc[i]['stop_time']\n",
    "        next_start = participant_segments.iloc[i + 1]['start_time']\n",
    "        gap_duration = next_start - current_end\n",
    "        insert_pause.append(gap_duration >= min_gap_for_pause)\n",
    "\n",
    "    # Estrai segmenti audio e inserisci pause quando necessario\n",
    "    audio_segments = []\n",
    "    pause_samples = np.zeros(int(pause_duration * sr), dtype=np.float32)\n",
    "\n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        audio_segments.append(audio[s:e])\n",
    "        \n",
    "        # Inserisci pausa se il gap era >= 2 secondi\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            audio_segments.append(pause_samples)\n",
    "    \n",
    "    cleaned_audio = np.concatenate(audio_segments)\n",
    "    \n",
    "    # Aggiorna timestamp considerando le pause inserite\n",
    "    current_time = 0.0\n",
    "    new_starts = []\n",
    "    new_stops = []\n",
    "    \n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        segment_duration = (e - s) / sr\n",
    "        new_starts.append(current_time)\n",
    "        current_time += segment_duration\n",
    "        new_stops.append(current_time)\n",
    "        \n",
    "        # Aggiungi tempo di pausa se inserita\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            current_time += pause_duration\n",
    "\n",
    "    # Aggiorna timestamp e rimuovi colonna speaker\n",
    "    participant_segments['start_time'] = new_starts\n",
    "    participant_segments['stop_time'] = new_stops\n",
    "    participant_segments = participant_segments.drop('speaker', axis=1)\n",
    "    \n",
    "    # Salva\n",
    "    sf.write(output_audio_path, cleaned_audio, sr, subtype='PCM_16')\n",
    "    participant_segments.to_csv(output_transcript_path, sep='\\t', index=False)\n",
    "    \n",
    "    original_duration = len(audio) / sr\n",
    "    cleaned_duration = len(cleaned_audio) / sr\n",
    "\n",
    "    return original_duration, cleaned_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd88443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 0 sessioni su 189 totali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sessions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Durata totale originale: 0.0s (0.00h)\n",
      "Durata totale dopo pulizia: 0.0s (0.00h)\n",
      "Durata totale rimossa: 0.0s (0.00h)\n",
      "Riduzione: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Elaborazione dataset - salva in directory separate\n",
    "dataset_configs = [\n",
    "    {\"input_dir\": \"datasets/DAIC-WOZ\", \"output_dir\": \"datasets/DAIC-WOZ-preprocessed\"},\n",
    "    {\"input_dir\": \"datasets/EDAIC-WOZ\", \"output_dir\": \"datasets/EDAIC-WOZ-preprocessed\"}\n",
    "]\n",
    "\n",
    "for config in dataset_configs:\n",
    "    dataset_dir = config[\"input_dir\"]\n",
    "    output_dir = config[\"output_dir\"]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    dataset_sessions = sorted([d for d in os.listdir(dataset_dir) \\\n",
    "                   if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "\n",
    "    print(f\"Processing {dataset_dir} -> {output_dir}\")\n",
    "    for session in tqdm(dataset_sessions, desc=f\"Processing {os.path.basename(dataset_dir)} sessions\"):\n",
    "        session_path = os.path.join(dataset_dir, session)\n",
    "        session_id = session.replace(\"_P\", \"\")\n",
    "\n",
    "        # Percorsi file input\n",
    "        audio_path = os.path.join(session_path, f\"{session_id}_AUDIO.wav\")\n",
    "        transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        # Percorsi file output\n",
    "        output_session_path = os.path.join(output_dir, session)\n",
    "        os.makedirs(output_session_path, exist_ok=True)\n",
    "        output_audio_path = os.path.join(output_session_path, f\"{session_id}_AUDIO.wav\")\n",
    "        output_transcript_path = os.path.join(output_session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        # Processa sessione\n",
    "        original_duration, cleaned_duration = clean_audio_and_transcript(\n",
    "            audio_path, transcript_path, output_audio_path, output_transcript_path, \n",
    "            buffer_sec=0.1, min_gap_for_pause=2.0, pause_duration=0.5\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171567b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_lengths(dataset_dir):\n",
    "    \"\"\"\n",
    "    Analizza le lunghezze degli audio per determinare parametri ottimali\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistiche delle durate\n",
    "    \"\"\"\n",
    "    print(\"Analizzando lunghezze audio...\")\n",
    "    durations = []\n",
    "    session_names = []\n",
    "    session_dirs = sorted([d for d in os.listdir(dataset_dir) \\\n",
    "                   if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "\n",
    "    for session in tqdm(session_dirs, desc=\"Analisi campione\"):\n",
    "        session_path = os.path.join(dataset_dir, session)\n",
    "        session_id = session.replace(\"_P\", \"\")\n",
    "        transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "        durations.append(transcript['stop_time'].max())\n",
    "        session_names.append(session_id) \n",
    "    \n",
    "    durations = np.array(durations)\n",
    "    min_idx = np.argmin(durations)\n",
    "    max_idx = np.argmax(durations)\n",
    "    \n",
    "    stats = {\n",
    "        'count': len(durations),\n",
    "        'mean': np.mean(durations),\n",
    "        'median': np.median(durations),\n",
    "        'std': np.std(durations),\n",
    "        'min': np.min(durations),\n",
    "        'max': np.max(durations),\n",
    "        'min_audio': session_names[min_idx],  # Nome audio con durata minima\n",
    "        'max_audio': session_names[max_idx],  # Nome audio con durata massima\n",
    "        'q25': np.percentile(durations, 25),\n",
    "        'q75': np.percentile(durations, 75)\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca86e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pitch_shift(audio, sr, n_steps):\n",
    "    \"\"\"\n",
    "    Applica pitch shift all'audio\n",
    "    \n",
    "    Args:\n",
    "        audio: Array audio\n",
    "        sr: Sample rate\n",
    "        n_steps: Numero di semitoni da spostare (+/- valori)\n",
    "    \n",
    "    Returns:\n",
    "        Audio con pitch modificato\n",
    "    \"\"\"\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def apply_tone_change_to_class1(dataset_dirs, labels_dict, percentage=0.2, pitch_steps=2):\n",
    "    \"\"\"\n",
    "    Applica tone change al percentuale specificata dei campioni di classe 1\n",
    "    \n",
    "    Args:\n",
    "        dataset_dirs: Lista delle directory dei dataset preprocessati\n",
    "        labels_dict: Dizionario con le etichette {session_id: label}\n",
    "        percentage: Percentuale di campioni da modificare\n",
    "        pitch_steps: Numero di semitoni per il pitch shift\n",
    "    \"\"\"\n",
    "    print(f\"Applicando tone change al {percentage*100}% dei campioni di classe 1...\")\n",
    "    \n",
    "    for dataset_dir in dataset_dirs:\n",
    "        print(f\"Processando {dataset_dir}...\")\n",
    "        \n",
    "        # Trova tutti i campioni di classe 1 nel dataset\n",
    "        class1_sessions = []\n",
    "        session_dirs = sorted([d for d in os.listdir(dataset_dir) \n",
    "                              if os.path.isdir(os.path.join(dataset_dir, d)) and d.endswith('_P')])\n",
    "        \n",
    "        for session in session_dirs:\n",
    "            session_id = session.replace('_P', '')\n",
    "            if labels_dict.get(session_id, 0) == 1:  # Classe 1 (depresso)\n",
    "                class1_sessions.append(session)\n",
    "        \n",
    "        print(f\"Trovati {len(class1_sessions)} campioni di classe 1 in {os.path.basename(dataset_dir)}\")\n",
    "        \n",
    "        if len(class1_sessions) == 0:\n",
    "            print(f\"Nessun campione di classe 1 trovato in {dataset_dir}\")\n",
    "            continue\n",
    "            \n",
    "        # Seleziona casualmente la percentuale specificata dei campioni di classe 1\n",
    "        num_to_modify = int(len(class1_sessions) * percentage)\n",
    "        if num_to_modify == 0:\n",
    "            print(f\"Nessun campione da modificare in {dataset_dir}\")\n",
    "            continue\n",
    "            \n",
    "        sessions_to_modify = random.sample(class1_sessions, num_to_modify)\n",
    "        \n",
    "        print(f\"Modificando {num_to_modify} campioni ({percentage*100}%) in {os.path.basename(dataset_dir)}\")\n",
    "        \n",
    "        # Applica tone change ai campioni selezionati\n",
    "        for session in tqdm(sessions_to_modify, desc=f\"Tone change {os.path.basename(dataset_dir)}\"):\n",
    "            session_path = os.path.join(dataset_dir, session)\n",
    "            session_id = session.replace('_P', '')\n",
    "            audio_path = os.path.join(session_path, f\"{session_id}_AUDIO.wav\")\n",
    "            \n",
    "            # Leggi audio\n",
    "            audio, sr = sf.read(audio_path)\n",
    "            \n",
    "            # Applica pitch shift\n",
    "            modified_audio = apply_pitch_shift(audio, sr, pitch_steps)\n",
    "            \n",
    "            # Sovrascrivi il file audio con la versione modificata\n",
    "            sf.write(audio_path, modified_audio, sr, subtype='PCM_16')\n",
    "            \n",
    "        print(f\"Tone change completato per {len(sessions_to_modify)} campioni in {os.path.basename(dataset_dir)}\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37492351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il dataset CSV per ottenere le etichette e la percentuale\n",
    "dataset_csv_path = \"datasets/dataset.csv\"\n",
    "dataset_df = pd.read_csv(dataset_csv_path)\n",
    "\n",
    "# Crea dizionario delle etichette\n",
    "labels_dict = dict(zip(dataset_df['session_id'].astype(str), dataset_df['label']))\n",
    "\n",
    "# Leggi la percentuale dal CSV (assumendo che ci sia una colonna 'tone_change_percentage')\n",
    "# Se non esiste, usa un valore di default\n",
    "if 'tone_change_percentage' in dataset_df.columns:\n",
    "    # Prendi il primo valore non-null della colonna percentuale\n",
    "    percentage = dataset_df['tone_change_percentage'].dropna().iloc[0] if not dataset_df['tone_change_percentage'].dropna().empty else 0.2\n",
    "else:\n",
    "    percentage = 0.2  # Default 20%\n",
    "\n",
    "print(f\"Percentuale per tone change: {percentage*100}%\")\n",
    "print(f\"Numero totale di sessioni: {len(labels_dict)}\")\n",
    "print(f\"Sessioni di classe 1: {sum(1 for v in labels_dict.values() if v == 1)}\")\n",
    "\n",
    "# Directory dei dataset preprocessati\n",
    "preprocessed_dirs = [\"datasets/DAIC-WOZ-preprocessed\", \"datasets/EDAIC-WOZ-preprocessed\"]\n",
    "\n",
    "# Applica tone change ai dataset preprocessati\n",
    "apply_tone_change_to_class1(preprocessed_dirs, labels_dict, percentage=percentage, pitch_steps=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
