{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cf8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "edaic_dir = \"../datasets/EDAIC-WOZ\"\n",
    "\n",
    "# Remove folders from 300 to 492\n",
    "for i in range(300, 493):\n",
    "    folder_name = f\"{i}_P\"\n",
    "    folder_path = os.path.join(edaic_dir, folder_name)\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "\n",
    "# XXX_P/XXX_P -> XXX_P\n",
    "for dir_name in os.listdir(edaic_dir):\n",
    "    outer_path = os.path.join(edaic_dir, dir_name)\n",
    "    if os.path.isdir(outer_path):\n",
    "        inner_path = os.path.join(outer_path, dir_name)\n",
    "        if os.path.isdir(inner_path):\n",
    "            # Sposta tutti i file dal secondo livello al primo\n",
    "            for filename in os.listdir(inner_path):\n",
    "                src = os.path.join(inner_path, filename)\n",
    "                dst = os.path.join(outer_path, filename)\n",
    "                shutil.move(src, dst)\n",
    "            # Rimuove la cartella interna vuota\n",
    "            os.rmdir(inner_path)\n",
    "\n",
    "# Csv files to concatenate\n",
    "csv_files = ['dev_split.csv', 'test_split.csv', 'train_split.csv']\n",
    "dfs = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    path = os.path.join(edaic_dir, csv_file)\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Filter from 300 to 492\n",
    "all_data = all_data[~all_data['Participant_ID'].between(300, 492)]\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(edaic_dir, \"all_data.csv\")\n",
    "all_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix inconsistent PHQ labels\n",
    "# Find participants with PHQ_Score >= 10 but PHQ_Binary = 0\n",
    "inconsistent_mask = (all_data['PHQ_Score'] >= 10) & (all_data['PHQ_Binary'] == 0)\n",
    "inconsistent_participants = all_data[inconsistent_mask]['Participant_ID'].tolist()\n",
    "\n",
    "print(f\"Found {len(inconsistent_participants)} participants with inconsistent PHQ labels:\")\n",
    "for participant_id in inconsistent_participants:\n",
    "    phq_score = all_data[all_data['Participant_ID'] == participant_id]['PHQ_Score'].iloc[0]\n",
    "    print(f\"  Participant {participant_id}: PHQ_Score={phq_score}, PHQ_Binary=0 -> fixing to PHQ_Binary=1\")\n",
    "\n",
    "# Fix the inconsistent labels\n",
    "all_data.loc[inconsistent_mask, 'PHQ_Binary'] = 1\n",
    "\n",
    "print(f\"\\nFixed {len(inconsistent_participants)} inconsistent labels\")\n",
    "\n",
    "# Save the corrected data\n",
    "all_data.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete directories for non-depressed participants (PHQ_Binary = 0)\n",
    "non_depressed_participants = all_data[all_data['PHQ_Binary'] == 0]['Participant_ID'].unique()\n",
    "\n",
    "print(f\"Found {len(non_depressed_participants)} non-depressed participants to remove:\")\n",
    "\n",
    "deleted_count = 0\n",
    "for participant_id in non_depressed_participants:\n",
    "    folder_name = f\"{participant_id}_P\"\n",
    "    folder_path = os.path.join(edaic_dir, folder_name)\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        deleted_count += 1\n",
    "\n",
    "print(f\"Deleted {deleted_count} directories for non-depressed participants\")\n",
    "\n",
    "# Remove non-depressed participants from the CSV data\n",
    "all_data = all_data[all_data['PHQ_Binary'] == 1]\n",
    "all_data.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
