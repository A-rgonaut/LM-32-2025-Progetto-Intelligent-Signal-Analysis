{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb58d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1d1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio_segment(audio_tensor, sample_rate):\n",
    "    # audio_tensor shape: [channels, samples]\n",
    "    audio_np = audio_tensor.numpy().T  # Trasponi per shape (samples, channels)\n",
    "    sd.play(audio_np, sample_rate)\n",
    "    sd.wait()\n",
    "\n",
    "def label_speakers(audio_path, transcript_path):\n",
    "    df = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    if df['speaker'].str.lower().isin({'ellie', 'participant', 'ignore'}).any():\n",
    "        print(f\"{transcript_path} Labeling already done, skipping.\")\n",
    "        return\n",
    "    speaker_labels = {}\n",
    "    speakers = df['speaker'].unique()\n",
    "\n",
    "    for spk in speakers:\n",
    "        # Trova il segmento più lungo per questo speaker\n",
    "        spk_segments = df[df['speaker'] == spk].copy()\n",
    "        spk_segments[\"duration\"] = spk_segments[\"stop_time\"] - spk_segments[\"start_time\"]\n",
    "        longest_seg = spk_segments.sort_values(\"duration\", ascending=False).iloc[0]\n",
    "\n",
    "        start_sample = int(longest_seg['start_time'] * sample_rate)\n",
    "        end_sample = int(longest_seg['stop_time'] * sample_rate)\n",
    "        segment_audio = waveform[:, start_sample:end_sample]\n",
    "\n",
    "        print(f\"\\nSpeaker: {spk} - playing **longest** segment from {start_sample/sample_rate:.2f}s to {end_sample/sample_rate:.2f}s \"\n",
    "              f\"({longest_seg['duration']:.2f}s long)\")\n",
    "        play_audio_segment(segment_audio, sample_rate)\n",
    "        choice = input(\"Label this speaker as (E)llie, (P)articipant, (O)ther: \").strip().lower()\n",
    "        if choice == 'e':\n",
    "            speaker_labels[spk] = \"Ellie\"\n",
    "        elif choice == 'p':\n",
    "            speaker_labels[spk] = \"Participant\"\n",
    "        else:\n",
    "            speaker_labels[spk] = \"ignore\"\n",
    "\n",
    "    df['speaker'] = df['speaker'].map(speaker_labels)\n",
    "    df.to_csv(transcript_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Updated transcript saved to {transcript_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a26847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing session 602_P ===\n",
      "../datasets/EDAIC-WOZ\\602_P\\602_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 604_P ===\n",
      "../datasets/EDAIC-WOZ\\604_P\\604_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 617_P ===\n",
      "../datasets/EDAIC-WOZ\\617_P\\617_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 624_P ===\n",
      "../datasets/EDAIC-WOZ\\624_P\\624_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 633_P ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  17%|█▋        | 5/30 [00:00<00:01, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/EDAIC-WOZ\\633_P\\633_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 636_P ===\n",
      "../datasets/EDAIC-WOZ\\636_P\\636_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 637_P ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  30%|███       | 9/30 [00:00<00:01, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/EDAIC-WOZ\\637_P\\637_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 638_P ===\n",
      "../datasets/EDAIC-WOZ\\638_P\\638_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 640_P ===\n",
      "../datasets/EDAIC-WOZ\\640_P\\640_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 641_P ===\n",
      "../datasets/EDAIC-WOZ\\641_P\\641_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 649_P ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  37%|███▋      | 11/30 [00:00<00:01, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/EDAIC-WOZ\\649_P\\649_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 655_P ===\n",
      "../datasets/EDAIC-WOZ\\655_P\\655_TRANSCRIPT.csv Labeling already done, skipping.\n",
      "\n",
      "=== Processing session 658_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 35.92s to 45.95s (10.02s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  37%|███▋      | 11/30 [00:20<00:01, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 143.25s to 179.81s (36.56s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 386.50s to 394.65s (8.15s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  43%|████▎     | 13/30 [01:45<04:44, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\658_P\\658_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 659_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 1262.45s to 1276.76s (14.31s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 493.11s to 515.04s (21.93s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  47%|████▋     | 14/30 [02:48<06:46, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\659_P\\659_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 661_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 495.21s to 499.39s (4.18s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 558.66s to 597.49s (38.83s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 36.18s to 44.43s (8.25s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  50%|█████     | 15/30 [04:49<11:21, 45.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\661_P\\661_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 673_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 0.74s to 21.13s (20.39s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 399.09s to 410.20s (11.11s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 78.28s to 97.90s (19.62s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  53%|█████▎    | 16/30 [06:29<13:32, 58.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\673_P\\673_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 677_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 34.35s to 60.44s (26.08s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 474.06s to 491.38s (17.33s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 829.93s to 830.03s (0.10s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  57%|█████▋    | 17/30 [07:42<13:20, 61.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\677_P\\677_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 680_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 98.92s to 121.36s (22.44s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 1364.15s to 1380.47s (16.31s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 11.58s to 23.88s (12.30s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  60%|██████    | 18/30 [09:33<14:53, 74.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\680_P\\680_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 682_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 88.81s to 110.11s (21.30s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 52.28s to 72.39s (20.11s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 482.18s to 489.93s (7.75s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  63%|██████▎   | 19/30 [11:08<14:42, 80.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\682_P\\682_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 684_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 60.16s to 117.58s (57.42s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 722.11s to 776.18s (54.07s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 684.62s to 686.91s (2.28s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  67%|██████▋   | 20/30 [13:31<16:15, 97.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\684_P\\684_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 688_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 3.35s to 28.94s (25.58s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 563.04s to 581.61s (18.57s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  70%|███████   | 21/30 [14:25<12:47, 85.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\688_P\\688_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 689_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 49.27s to 55.68s (6.41s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 304.57s to 311.62s (7.05s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 160.76s to 177.93s (17.16s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  73%|███████▎  | 22/30 [15:26<10:25, 78.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\689_P\\689_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 691_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 283.11s to 297.96s (14.86s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 627.14s to 652.15s (25.01s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  77%|███████▋  | 23/30 [16:23<08:24, 72.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\691_P\\691_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 696_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 288.49s to 322.80s (34.31s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 261.85s to 271.69s (9.84s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 369.02s to 369.43s (0.40s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  80%|████████  | 24/30 [17:48<07:35, 75.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\696_P\\696_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 698_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 0.03s to 41.34s (41.31s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 557.50s to 614.45s (56.96s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  83%|████████▎ | 25/30 [19:34<07:03, 84.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\698_P\\698_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 699_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 8.57s to 24.79s (16.22s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 103.53s to 125.31s (21.78s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 280.22s to 291.09s (10.88s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  87%|████████▋ | 26/30 [20:50<05:28, 82.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\699_P\\699_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 705_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 44.75s to 64.11s (19.36s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 660.45s to 671.14s (10.69s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  90%|█████████ | 27/30 [21:51<03:47, 75.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\705_P\\705_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 709_P ===\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 0.03s to 58.55s (58.52s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 93.50s to 123.07s (29.57s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 449.44s to 452.78s (3.34s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  93%|█████████▎| 28/30 [23:40<02:51, 85.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\709_P\\709_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 716_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 30.39s to 50.09s (19.70s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 60.90s to 86.86s (25.97s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 180.58s to 198.87s (18.29s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers: 100%|██████████| 30/30 [24:52<00:00, 49.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/EDAIC-WOZ\\716_P\\716_TRANSCRIPT.csv\n",
      "Skipping temp_results: missing audio or transcript file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "edaic_dir = \"../datasets/EDAIC-WOZ\"\n",
    "\n",
    "# Process all sessions for speaker labeling\n",
    "sessions = sorted([d for d in os.listdir(edaic_dir) if os.path.isdir(os.path.join(edaic_dir, d))])\n",
    "\n",
    "for session in tqdm(sessions, desc=\"Labeling speakers\"):\n",
    "    session_path = os.path.join(edaic_dir, session)\n",
    "    base_name = session.split(\"_\")[0]\n",
    "    audio_path = os.path.join(session_path, f\"{base_name}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(session_path, f\"{base_name}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    if os.path.exists(audio_path) and os.path.exists(transcript_path):\n",
    "        print(f\"\\n=== Processing session {session} ===\")\n",
    "        try:\n",
    "            label_speakers(audio_path, transcript_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {session}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Skipping {session}: missing audio or transcript file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14710a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing session 318_P ===\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 9.61s to 17.49s (7.89s long)\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 391.36s to 412.69s (21.33s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  25%|██▌       | 1/4 [01:17<03:52, 77.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/DAIC-WOZ\\318_P\\318_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 321_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 11.08s to 17.87s (6.79s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 326.49s to 357.14s (30.65s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 37.85s to 65.64s (27.79s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  50%|█████     | 2/4 [04:02<04:17, 128.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/DAIC-WOZ\\321_P\\321_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 341_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 9.12s to 14.30s (5.19s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 385.29s to 405.64s (20.35s long)\n",
      "\n",
      "Speaker: SPEAKER_02 - playing **longest** segment from 68.31s to 73.19s (4.89s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers:  75%|███████▌  | 3/4 [13:39<05:33, 333.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/DAIC-WOZ\\341_P\\341_TRANSCRIPT.csv\n",
      "\n",
      "=== Processing session 362_P ===\n",
      "\n",
      "Speaker: SPEAKER_01 - playing **longest** segment from 479.98s to 491.53s (11.56s long)\n",
      "\n",
      "Speaker: SPEAKER_00 - playing **longest** segment from 552.00s to 560.80s (8.79s long)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling speakers: 100%|██████████| 4/4 [14:43<00:00, 220.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated transcript saved to ../datasets/DAIC-WOZ\\362_P\\362_TRANSCRIPT.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "daic_dir = \"../datasets/DAIC-WOZ\" \n",
    "\n",
    "sessions = [\"318_P\", \"321_P\", \"341_P\", \"362_P\"] # https://github.com/adbailey1/daic_woz_process/tree/master\n",
    "\n",
    "for session in tqdm(sessions, desc=\"Labeling speakers\"):\n",
    "    session_path = os.path.join(daic_dir, session)\n",
    "    base_name = session.split(\"_\")[0]\n",
    "    audio_path = os.path.join(session_path, f\"{base_name}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(session_path, f\"{base_name}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    if os.path.exists(audio_path) and os.path.exists(transcript_path):\n",
    "        print(f\"\\n=== Processing session {session} ===\")\n",
    "        try:\n",
    "            label_speakers(audio_path, transcript_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {session}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Skipping {session}: missing audio or transcript file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
