{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sounddevice as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio_segment(audio_tensor, sample_rate):\n",
    "    # audio_tensor shape: [channels, samples]\n",
    "    audio_np = audio_tensor.numpy().T  # Trasponi per shape (samples, channels)\n",
    "    sd.play(audio_np, sample_rate)\n",
    "    sd.wait()\n",
    "\n",
    "def label_speakers(audio_path, transcript_path):\n",
    "    df = pd.read_csv(transcript_path, sep=\"\\t\")\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    speaker_labels = {}\n",
    "    speakers = df['speaker'].unique()\n",
    "\n",
    "    for spk in speakers:\n",
    "        # Trova il segmento più lungo per questo speaker\n",
    "        spk_segments = df[df['speaker'] == spk].copy()\n",
    "        spk_segments[\"duration\"] = spk_segments[\"stop_time\"] - spk_segments[\"start_time\"]\n",
    "        longest_seg = spk_segments.sort_values(\"duration\", ascending=False).iloc[0]\n",
    "\n",
    "        start_sample = int(longest_seg['start_time'] * sample_rate)\n",
    "        end_sample = int(longest_seg['stop_time'] * sample_rate)\n",
    "        segment_audio = waveform[:, start_sample:end_sample]\n",
    "\n",
    "        print(f\"\\nSpeaker: {spk} - playing **longest** segment from {start_sample/sample_rate:.2f}s to {end_sample/sample_rate:.2f}s \"\n",
    "              f\"({longest_seg['duration']:.2f}s long)\")\n",
    "        play_audio_segment(segment_audio, sample_rate)\n",
    "\n",
    "        choice = input(\"Label this speaker as (E)llie, (P)articipant, (O)ther: \").strip().lower()\n",
    "        if choice == 'e':\n",
    "            speaker_labels[spk] = \"Ellie\"\n",
    "        elif choice == 'p':\n",
    "            speaker_labels[spk] = \"Participant\"\n",
    "        else:\n",
    "            speaker_labels[spk] = \"ignore\"\n",
    "\n",
    "    df['speaker'] = df['speaker'].map(speaker_labels)\n",
    "    df.to_csv(transcript_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Updated transcript saved to {transcript_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edaic_dir = \"../datasets/EDAIC-WOZ\"\n",
    "\n",
    "# Process all sessions for speaker labeling\n",
    "sessions = sorted([d for d in os.listdir(edaic_dir) if os.path.isdir(os.path.join(edaic_dir, d))])\n",
    "\n",
    "for session in tqdm(sessions, desc=\"Labeling speakers\"):\n",
    "    session_path = os.path.join(edaic_dir, session)\n",
    "    base_name = session.split(\"_\")[0]\n",
    "    audio_path = os.path.join(session_path, f\"{base_name}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(session_path, f\"{base_name}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    if os.path.exists(audio_path) and os.path.exists(transcript_path):\n",
    "        print(f\"\\n=== Processing session {session} ===\")\n",
    "        try:\n",
    "            label_speakers(audio_path, transcript_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {session}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Skipping {session}: missing audio or transcript file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14710a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "daic_dir = \"../datasets/DAIC-WOZ\" \n",
    "\n",
    "sessions = [\"318\", \"321\", \"341\", \"362\"] # https://github.com/adbailey1/daic_woz_process/tree/master\n",
    "\n",
    "for session in tqdm(sessions, desc=\"Labeling speakers\"):\n",
    "    session_path = os.path.join(daic_dir, session)\n",
    "    base_name = session.split(\"_\")[0]\n",
    "    audio_path = os.path.join(session_path, f\"{base_name}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(session_path, f\"{base_name}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    if os.path.exists(audio_path) and os.path.exists(transcript_path):\n",
    "        print(f\"\\n=== Processing session {session} ===\")\n",
    "        try:\n",
    "            label_speakers(audio_path, transcript_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {session}: {e}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"Skipping {session}: missing audio or transcript file\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
