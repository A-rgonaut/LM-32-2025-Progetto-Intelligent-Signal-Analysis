{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cad73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, f1_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from utils import load_labels_from_dataset, get_audio_paths\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc12a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementazione dell'architettura CNN+MLP descritta nel paper.\n",
    "    La rete accetta in input segmenti di waveform audio (1D).\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_rate=0.5, num_classes=2):\n",
    "        super(CNNMLP, self).__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=64, stride=1),\n",
    "            nn.BatchNorm1d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=32, stride=1),\n",
    "            nn.BatchNorm1d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=16, stride=1),\n",
    "            nn.BatchNorm1d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p=dropout_rate)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp_block = nn.Sequential(\n",
    "            nn.Linear(in_features=1, out_features=128), # Will be initialized dynamically\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features=128, out_features=num_classes)\n",
    "        )\n",
    "        self._mlp_initialized = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x_flattened = self.flatten(x)\n",
    "        if not self._mlp_initialized:\n",
    "            in_features = x_flattened.shape[1]\n",
    "            self.mlp_block[0] = nn.Linear(in_features, 128).to(x.device)\n",
    "            print(f\"MLP inizializzato dinamicamente con {in_features} feature di input.\")\n",
    "            self._mlp_initialized = True\n",
    "        output = self.mlp_block(x_flattened)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "672a57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioSegmentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset PyTorch generico per caricare e segmentare file audio.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_paths, labels, sr=16000, segment_ms=250, hop_ms=50):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.segment_length = int(sr * (segment_ms / 1000.0))\n",
    "        self.hop_length = int(sr * (hop_ms / 1000.0))\n",
    "        self.segments = []\n",
    "        self.segment_labels = []\n",
    "        self.file_indices = []  # To track which file each segment belongs to\n",
    "        self._create_segments()\n",
    "\n",
    "    def _create_segments(self):\n",
    "        print(\"Creazione dei segmenti dal dataset...\")\n",
    "        for i, file_path in enumerate(self.file_paths):\n",
    "            label = self.labels[i]\n",
    "            try:\n",
    "                waveform, original_sr = librosa.load(file_path, sr=self.sr)\n",
    "                if np.max(np.abs(waveform)) > 0:\n",
    "                    waveform = waveform / np.max(np.abs(waveform))\n",
    "                start = 0\n",
    "                while start + self.segment_length <= len(waveform):\n",
    "                    segment = waveform[start : start + self.segment_length]\n",
    "                    self.segments.append(segment)\n",
    "                    self.segment_labels.append(label)\n",
    "                    self.file_indices.append(i)\n",
    "                    start += self.hop_length\n",
    "            except Exception as e:\n",
    "                print(f\"Errore durante l'elaborazione del file {file_path}: {e}\")\n",
    "        print(f\"Creati {len(self.segments)} segmenti totali.\")\n",
    "\n",
    "    def get_segments_for_file(self, file_path):\n",
    "        \"\"\"Get all segments for a specific file\"\"\"\n",
    "        try:\n",
    "            waveform, _ = librosa.load(file_path, sr=self.sr)\n",
    "            if np.max(np.abs(waveform)) > 0:\n",
    "                waveform = waveform / np.max(np.abs(waveform))\n",
    "            \n",
    "            segments = []\n",
    "            start = 0\n",
    "            while start + self.segment_length <= len(waveform):\n",
    "                segment = waveform[start : start + self.segment_length]\n",
    "                segments.append(segment)\n",
    "                start += self.hop_length\n",
    "            \n",
    "            if segments:\n",
    "                segments_tensor = torch.stack([torch.tensor(seg, dtype=torch.float32).unsqueeze(0) for seg in segments])\n",
    "                return segments_tensor, None\n",
    "            else:\n",
    "                return torch.empty(0), None\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante l'elaborazione del file {file_path}: {e}\")\n",
    "            return torch.empty(0), None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        segment = self.segments[idx]\n",
    "        label = self.segment_labels[idx]\n",
    "        segment_tensor = torch.tensor(segment, dtype=torch.float32).unsqueeze(0)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return segment_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cb60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = -np.inf if mode == 'max' else np.inf\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.mode == 'max':\n",
    "            improvement = (current_score - self.best_score) > self.min_delta\n",
    "        else:\n",
    "            improvement = (self.best_score - current_score) > self.min_delta\n",
    "\n",
    "        if improvement:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True  # Early stop\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31c83713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss, correct_predictions = 0, 0\n",
    "    train_pbar = tqdm(enumerate(data_loader), \n",
    "                      total=len(data_loader),\n",
    "                      desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n",
    "    \n",
    "    for batch_idx, (batch_segments, batch_labels) in train_pbar:\n",
    "        batch_segments = batch_segments.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_segments)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, batch_labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate predictions for multi-class classification\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += torch.sum(preds == batch_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct_predictions.double() / len(data_loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_on_full_files(model, file_paths, labels, device, sr=16000, segment_ms=250, hop_ms=50):\n",
    "    \"\"\"Evaluate model on complete audio files by averaging segment predictions\"\"\"\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    \n",
    "    segment_length = int(sr * (segment_ms / 1000.0))\n",
    "    hop_length = int(sr * (hop_ms / 1000.0))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for file_path, label in tqdm(zip(file_paths, labels), desc=\"Evaluating on full files\", total=len(file_paths)):\n",
    "            try:\n",
    "                # Load and segment the audio file\n",
    "                waveform, _ = librosa.load(file_path, sr=sr)\n",
    "                if np.max(np.abs(waveform)) > 0:\n",
    "                    waveform = waveform / np.max(np.abs(waveform))\n",
    "                \n",
    "                segments = []\n",
    "                start = 0\n",
    "                while start + segment_length <= len(waveform):\n",
    "                    segment = waveform[start : start + segment_length]\n",
    "                    segments.append(segment)\n",
    "                    start += hop_length\n",
    "                \n",
    "                if not segments:\n",
    "                    continue\n",
    "                \n",
    "                # Convert to tensor and add channel dimension\n",
    "                segments_tensor = torch.stack([torch.tensor(seg, dtype=torch.float32).unsqueeze(0) for seg in segments])\n",
    "                segments_tensor = segments_tensor.to(device)\n",
    "                \n",
    "                # Get predictions for all segments\n",
    "                segment_outputs = model(segments_tensor)\n",
    "                segment_probs = torch.softmax(segment_outputs, dim=1)\n",
    "                \n",
    "                # Average probabilities across segments\n",
    "                avg_probs = torch.mean(segment_probs, dim=0)\n",
    "                final_prediction = torch.argmax(avg_probs).item()\n",
    "                \n",
    "                all_predictions.append(final_prediction)\n",
    "                all_targets.append(label)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    return np.array(all_targets), np.array(all_predictions)\n",
    "\n",
    "def eval_model(model, file_paths, labels, loss_fn, device, sr=16000, segment_ms=250, hop_ms=50):\n",
    "    \"\"\"Evaluation function similar to SSL fine-tuning\"\"\"\n",
    "    targets, predictions = evaluate_on_full_files(model, file_paths, labels, device, sr, segment_ms, hop_ms)\n",
    "    \n",
    "    if len(targets) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    f1 = f1_score(targets, predictions, average='macro')\n",
    "    \n",
    "    # Calculate a dummy loss (since we don't have segments with labels for full files)\n",
    "    loss = 0.0\n",
    "    \n",
    "    return loss, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e798c6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 107, Labels: 107\n",
      "Validation files: 35, Labels: 35\n",
      "Test files: 47, Labels: 47\n",
      "Creazione dei segmenti dal dataset...\n",
      "Creati 1050247 segmenti totali.\n",
      "\n",
      "Model initialized with 51026 parameters\n",
      "Creati 1050247 segmenti totali.\n",
      "\n",
      "Model initialized with 51026 parameters\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "dataset_name = \"datasets/DAIC-WOZ-Cleaned\"\n",
    "num_classes = 2\n",
    "\n",
    "# Load data splits\n",
    "train_df = pd.read_csv(os.path.join(dataset_name, 'train_split_Depression_AVEC2017.csv'))\n",
    "dev_df = pd.read_csv(os.path.join(dataset_name, 'dev_split_Depression_AVEC2017.csv'))\n",
    "test_df = pd.read_csv(os.path.join(dataset_name, 'full_test_split.csv'))\n",
    "\n",
    "# Extract labels and paths\n",
    "y_train = load_labels_from_dataset(train_df)\n",
    "y_dev = load_labels_from_dataset(dev_df) \n",
    "y_test = load_labels_from_dataset(test_df)\n",
    "\n",
    "train_paths = get_audio_paths(train_df, dataset_name)\n",
    "dev_paths = get_audio_paths(dev_df, dataset_name)\n",
    "test_paths = get_audio_paths(test_df, dataset_name)\n",
    "\n",
    "print(f\"Training files: {len(train_paths)}, Labels: {len(y_train)}\")\n",
    "print(f\"Validation files: {len(dev_paths)}, Labels: {len(y_dev)}\")\n",
    "print(f\"Test files: {len(test_paths)}, Labels: {len(y_test)}\")\n",
    "\n",
    "# Audio processing parameters\n",
    "SR = 16000\n",
    "SEGMENT_MS = 250\n",
    "HOP_MS = 50\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AudioSegmentDataset(\n",
    "    train_paths, y_train, sr=SR, segment_ms=SEGMENT_MS, hop_ms=HOP_MS\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "DROPOUT_RATE = 0.5\n",
    "model = CNNMLP(dropout_rate=DROPOUT_RATE, num_classes=num_classes).to(device)\n",
    "\n",
    "print(f\"\\nModel initialized with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaca275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Starting Training ===\n",
      "\n",
      "=== Epoch 1/20 ===\n"
     ]
    }
   ],
   "source": [
    "# Training configuration (similar to SSL fine-tuning)\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.005, mode='max')\n",
    "model_save_path = \"depression_cnn_classifier_best.pth\"\n",
    "\n",
    "# Training loop (similar structure to SSL fine-tuning)\n",
    "best_val_f1 = -np.inf\n",
    "best_model_weights = None\n",
    "\n",
    "print(\"=== Starting Training ===\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n=== Epoch {epoch + 1}/{NUM_EPOCHS} ===\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, \n",
    "        train_loader, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        device,\n",
    "        epoch,\n",
    "        NUM_EPOCHS\n",
    "    )\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Validation on full files\n",
    "    val_loss, val_acc, val_f1 = eval_model(\n",
    "        model, \n",
    "        dev_paths, \n",
    "        y_dev, \n",
    "        criterion, \n",
    "        device,\n",
    "        sr=SR,\n",
    "        segment_ms=SEGMENT_MS,\n",
    "        hop_ms=HOP_MS\n",
    "    )\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_f1 > best_val_f1 + early_stopping.min_delta:\n",
    "        best_val_f1 = val_f1 \n",
    "        best_model_weights = model.state_dict().copy()\n",
    "        print(f\"New best F1: {best_val_f1:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if early_stopping(val_f1):\n",
    "        print(f\"Early stopping activated. Best F1: {best_val_f1:.4f}\")\n",
    "        break\n",
    "\n",
    "print(\"Training Completed\")\n",
    "print(f\"Best F1 Score: {best_val_f1:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "if best_model_weights:\n",
    "    torch.save(best_model_weights, model_save_path)\n",
    "    print(f\"Best model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "print(\"\\n=== Test Evaluation ===\")\n",
    "\n",
    "# Load best model if available\n",
    "if best_model_weights:\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    print(\"Best model weights loaded for testing\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1 = eval_model(\n",
    "    model, \n",
    "    test_paths, \n",
    "    y_test, \n",
    "    criterion, \n",
    "    device,\n",
    "    sr=SR,\n",
    "    segment_ms=SEGMENT_MS,\n",
    "    hop_ms=HOP_MS\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Test Results ===\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}\")\n",
    "\n",
    "# Additional detailed evaluation\n",
    "targets, predictions = evaluate_on_full_files(\n",
    "    model, test_paths, y_test, device, sr=SR, segment_ms=SEGMENT_MS, hop_ms=HOP_MS\n",
    ")\n",
    "\n",
    "if len(targets) > 0:\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    print(\"\\n=== Detailed Test Results ===\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(targets, predictions, target_names=['Non-Depressed', 'Depressed']))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nSensitivity (Recall for Depressed): {sensitivity:.4f}\")\n",
    "    print(f\"Specificity (Recall for Non-Depressed): {specificity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
