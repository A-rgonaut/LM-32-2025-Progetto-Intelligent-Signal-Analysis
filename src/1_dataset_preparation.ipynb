{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd08940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "119ed8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_global_csv_files(src_dir, dst_dir):\n",
    "    \"\"\"\n",
    "    Copy all CSV files from the root of src_dir to dst_dir.\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(src_dir):\n",
    "        src_path = os.path.join(src_dir, fname)\n",
    "        dst_path = os.path.join(dst_dir, fname)\n",
    "        if fname.endswith(\".csv\") and os.path.isfile(src_path):\n",
    "            shutil.copy(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e47770c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sessions_to_process(dataset_dir, output_dir=None):\n",
    "    session_dirs = [d for d in os.listdir(dataset_dir) if d.endswith(\"_P\")]\n",
    "    session_dirs = [d for d in session_dirs if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "    if output_dir is not None:\n",
    "        return [s for s in session_dirs if not os.path.exists(os.path.join(output_dir, s))]\n",
    "    return session_dirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b79ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_audio_and_transcript(input_audio_path, transcript_path, output_audio_path, output_transcript_path,\n",
    "                               buffer_sec=0.1, min_gap_for_pause=2.0, pause_duration=0.5):\n",
    "    \"\"\"\n",
    "    Clean audio and transcript by extracting only participant segments\n",
    "    \n",
    "    Args:\n",
    "        input_audio_path: Path to input audio file\n",
    "        transcript_path: Path to input transcript CSV\n",
    "        output_audio_path: Path for cleaned audio output\n",
    "        output_transcript_path: Path for cleaned transcript output\n",
    "        buffer_sec: Buffer time in seconds to add around segments\n",
    "        min_gap_for_pause: Minimum gap between segments to insert a pause (seconds)\n",
    "        pause_duration: Duration of inserted pause (seconds)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (original_duration, cleaned_duration)\n",
    "    \"\"\"\n",
    "    # Lettura file\n",
    "    audio, sr = sf.read(input_audio_path)\n",
    "    transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "\n",
    "    # Filtra solo segmenti partecipante\n",
    "    participant_segments = transcript[\n",
    "        (transcript['speaker'] == 'Participant') &\n",
    "        (~transcript['value'].str.contains('scrubbed_entry|<synch>|<sync>', na=False))\n",
    "    ].copy()\n",
    "    \n",
    "    # Calcola posizioni in samples e aggiungi buffer\n",
    "    buffer_samples = int(buffer_sec * sr)\n",
    "    starts = ((participant_segments['start_time'] * sr).astype(np.int32) - buffer_samples).clip(lower=0)\n",
    "    ends = ((participant_segments['stop_time'] * sr).astype(np.int32) + buffer_samples).clip(upper=len(audio))\n",
    "\n",
    "    # Controlla gap tra segmenti consecutivi del partecipante\n",
    "    insert_pause = []\n",
    "    for i in range(len(participant_segments) - 1):\n",
    "        current_end = participant_segments.iloc[i]['stop_time']\n",
    "        next_start = participant_segments.iloc[i + 1]['start_time']\n",
    "        gap_duration = next_start - current_end\n",
    "        insert_pause.append(gap_duration >= min_gap_for_pause)\n",
    "\n",
    "    # Estrai segmenti audio e inserisci pause quando necessario\n",
    "    audio_segments = []\n",
    "    pause_samples = np.zeros(int(pause_duration * sr), dtype=np.float32)\n",
    "\n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        audio_segments.append(audio[s:e])\n",
    "        \n",
    "        # Inserisci pausa se il gap era >= 2 secondi\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            audio_segments.append(pause_samples)\n",
    "    \n",
    "    cleaned_audio = np.concatenate(audio_segments)\n",
    "    \n",
    "    # Aggiorna timestamp considerando le pause inserite\n",
    "    current_time = 0.0\n",
    "    new_starts = []\n",
    "    new_stops = []\n",
    "    \n",
    "    for i, (s, e) in enumerate(zip(starts, ends)):\n",
    "        segment_duration = (e - s) / sr\n",
    "        new_starts.append(current_time)\n",
    "        current_time += segment_duration\n",
    "        new_stops.append(current_time)\n",
    "        \n",
    "        # Aggiungi tempo di pausa se inserita\n",
    "        if i < len(insert_pause) and insert_pause[i]:\n",
    "            current_time += pause_duration\n",
    "\n",
    "    # Aggiorna timestamp e rimuovi colonna speaker\n",
    "    participant_segments['start_time'] = new_starts\n",
    "    participant_segments['stop_time'] = new_stops\n",
    "    participant_segments = participant_segments.drop('speaker', axis=1)\n",
    "    \n",
    "    # Salva\n",
    "    sf.write(output_audio_path, cleaned_audio, sr, subtype='PCM_16')\n",
    "    participant_segments.to_csv(output_transcript_path, sep='\\t', index=False)\n",
    "    \n",
    "    original_duration = len(audio) / sr\n",
    "    cleaned_duration = len(cleaned_audio) / sr\n",
    "\n",
    "    return original_duration, cleaned_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cd88443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 0 sessioni su 189 totali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sessions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Durata totale originale: 0.0s (0.00h)\n",
      "Durata totale dopo pulizia: 0.0s (0.00h)\n",
      "Durata totale rimossa: 0.0s (0.00h)\n",
      "Riduzione: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Elaborazione dataset\n",
    "dataset_dir = \"datasets/DAIC-WOZ\"\n",
    "output_dir = \"datasets/DAIC-WOZ-Cleaned\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "total_original = 0.0\n",
    "total_cleaned = 0.0\n",
    "\n",
    "sessions_to_process = get_sessions_to_process(dataset_dir, output_dir)\n",
    "\n",
    "print(f\"Processando {len(sessions_to_process)} sessioni su {len([d for d in os.listdir(dataset_dir) if d.endswith('_P')])} totali\")\n",
    "\n",
    "for session in tqdm(sessions_to_process, desc=\"Processing sessions\"):\n",
    "    session_path = os.path.join(dataset_dir, session)\n",
    "    session_id = session.replace(\"_P\", \"\")\n",
    "\n",
    "    # Percorsi file input\n",
    "    audio_path = os.path.join(session_path, f\"{session_id}_AUDIO.wav\")\n",
    "    transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    # Percorsi file output\n",
    "    output_session_path = os.path.join(output_dir, session)\n",
    "    os.makedirs(output_session_path, exist_ok=True)\n",
    "    output_audio_path = os.path.join(output_session_path, f\"{session_id}_AUDIO.wav\")\n",
    "    output_transcript_path = os.path.join(output_session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "    \n",
    "    # Processa sessione\n",
    "    original_duration, cleaned_duration = clean_audio_and_transcript(\n",
    "        audio_path, transcript_path, output_audio_path, output_transcript_path, \n",
    "        buffer_sec=0.1, min_gap_for_pause=2.0, pause_duration=0.5\n",
    "    )    \n",
    "    total_original += original_duration\n",
    "    total_cleaned += cleaned_duration\n",
    "\n",
    "total_removed = total_original - total_cleaned\n",
    "reduction_percentage = (total_removed / total_original * 100) if total_original > 0 else 0\n",
    "print(f\"\\nDurata totale originale: {total_original:.1f}s ({total_original/3600:.2f}h)\")\n",
    "print(f\"Durata totale dopo pulizia: {total_cleaned:.1f}s ({total_cleaned/3600:.2f}h)\")\n",
    "print(f\"Durata totale rimossa: {total_removed:.1f}s ({total_removed/3600:.2f}h)\")\n",
    "print(f\"Riduzione: {reduction_percentage:.1f}%\")\n",
    "\n",
    "# Copia i CSV globali dalla radice del dataset nella cartella cleaned\n",
    "copy_global_csv_files(dataset_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a2ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_split_Depression_AVEC2017.csv - distribuzione: [23 12], percentuali: [65.71 34.29] %\n",
      "train_split_Depression_AVEC2017.csv - distribuzione: [77 30], percentuali: [71.96 28.04] %\n",
      "full_test_split.csv - distribuzione: [33 14], percentuali: [70.21 29.79] %\n"
     ]
    }
   ],
   "source": [
    "# Stampa la distribuzione delle classi per ogni CSV globale copiato\n",
    "csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(output_dir, csv_file))\n",
    "    label_col = 'PHQ8_Binary' if 'PHQ8_Binary' in df.columns else ('PHQ_Binary' if 'PHQ_Binary' in df.columns else None)\n",
    "    if label_col:\n",
    "        counts = np.bincount(df[label_col].astype(int))\n",
    "        percentages = np.round(100 * counts / counts.sum(), 2)\n",
    "        print(f\"{csv_file} - distribuzione: {counts}, percentuali: {percentages} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "171567b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_audio_lengths(dataset_dir):\n",
    "    \"\"\"\n",
    "    Analizza le lunghezze degli audio per determinare parametri ottimali\n",
    "    \n",
    "    Returns:\n",
    "        dict: Statistiche delle durate\n",
    "    \"\"\"\n",
    "    print(\"Analizzando lunghezze audio...\")\n",
    "    durations = []\n",
    "    session_names = []\n",
    "    session_dirs = get_sessions_to_process(dataset_dir)\n",
    "\n",
    "    for session in tqdm(session_dirs, desc=\"Analisi campione\"):\n",
    "        session_path = os.path.join(dataset_dir, session)\n",
    "        session_id = session.replace(\"_P\", \"\")\n",
    "        transcript_path = os.path.join(session_path, f\"{session_id}_TRANSCRIPT.csv\")\n",
    "        \n",
    "        transcript = pd.read_csv(transcript_path, sep='\\t')\n",
    "        durations.append(transcript['stop_time'].max())\n",
    "        session_names.append(session_id) \n",
    "    \n",
    "    durations = np.array(durations)\n",
    "    min_idx = np.argmin(durations)\n",
    "    max_idx = np.argmax(durations)\n",
    "    \n",
    "    stats = {\n",
    "        'count': len(durations),\n",
    "        'mean': np.mean(durations),\n",
    "        'median': np.median(durations),\n",
    "        'std': np.std(durations),\n",
    "        'min': np.min(durations),\n",
    "        'max': np.max(durations),\n",
    "        'min_audio': session_names[min_idx],  # Nome audio con durata minima\n",
    "        'max_audio': session_names[max_idx],  # Nome audio con durata massima\n",
    "        'q25': np.percentile(durations, 25),\n",
    "        'q75': np.percentile(durations, 75)\n",
    "    }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a8a1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizzando lunghezze audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analisi campione: 100%|██████████| 189/189 [00:00<00:00, 1475.50it/s]\n",
      "Analisi campione: 100%|██████████| 189/189 [00:00<00:00, 1475.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'count': 189,\n",
       " 'mean': 526.5888591269842,\n",
       " 'median': 479.9799375000002,\n",
       " 'std': 245.74184613563557,\n",
       " 'min': 97.00993750000004,\n",
       " 'max': 1375.119875000002,\n",
       " 'min_audio': '385',\n",
       " 'max_audio': '337',\n",
       " 'q25': 352.1799374999998,\n",
       " 'q75': 648.8420000000001}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_audio_lengths(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f712e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando 0 sessioni su 189 totali\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sessions: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutte le sessioni processate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametri\n",
    "dataset_dir = \"datasets/DAIC-WOZ-Cleaned\"\n",
    "output_dir = \"datasets/DAIC-WOZ-Cleaned-Split\"\n",
    "segment_duration_sec = 10\n",
    "min_segment_duration_sec = 2  # Minimum duration for saving a segment\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "sessions_to_process = get_sessions_to_process(dataset_dir, output_dir)\n",
    "\n",
    "print(f\"Processando {len(sessions_to_process)} sessioni su {len([d for d in os.listdir(dataset_dir) if d.endswith('_P')])} totali\")\n",
    "\n",
    "for session in tqdm(sessions_to_process, desc=\"Processing sessions\"):\n",
    "    session_path = os.path.join(dataset_dir, session)\n",
    "    output_session_path = os.path.join(output_dir, session)\n",
    "    os.makedirs(output_session_path, exist_ok=True)\n",
    "    \n",
    "    session_id = session.replace(\"_P\", \"\")\n",
    "    audio_filename = f\"{session_id}_AUDIO.wav\"\n",
    "    audio_path = os.path.join(session_path, audio_filename)\n",
    "    \n",
    "    if not os.path.exists(audio_path):\n",
    "        print(f\"Audio file mancante per sessione {session}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Carica audio\n",
    "    audio, sr = sf.read(audio_path)\n",
    "    total_samples = len(audio)\n",
    "    segment_samples = segment_duration_sec * sr\n",
    "    num_parts = (total_samples + segment_samples - 1) // segment_samples\n",
    "    \n",
    "    for i in range(num_parts):\n",
    "        start = i * segment_samples\n",
    "        end = min(start + segment_samples, total_samples)\n",
    "        segment = audio[start:end]\n",
    "        segment_duration = len(segment) / sr\n",
    "        \n",
    "        if segment_duration >= min_segment_duration_sec:\n",
    "            out_filename = f\"{session_id}_AUDIO_part{i}.wav\"\n",
    "            out_path = os.path.join(output_session_path, out_filename)\n",
    "            sf.write(out_path, segment, sr)\n",
    "    \n",
    "print(\"Tutte le sessioni processate.\")\n",
    "\n",
    "# Copia i CSV globali dalla radice del dataset cleaned nella cartella cleaned-split\n",
    "copy_global_csv_files(dataset_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d27131f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_split_Depression_AVEC2017.csv - segmenti 10s: [1201, 801], percentuali: [59.99 40.01] %\n",
      "train_split_Depression_AVEC2017.csv - segmenti 10s: [3800, 1490], percentuali: [71.83 28.17] %\n",
      "full_test_split.csv - segmenti 10s: [1959, 762], percentuali: [72. 28.] %\n"
     ]
    }
   ],
   "source": [
    "# Analisi distribuzione segmenti da 10s per split (train/dev/test) dopo lo split\n",
    "split_dir = output_dir  # es: 'datasets/DAIC-WOZ-Cleaned-Split'\n",
    "csv_files = [f for f in os.listdir(split_dir) if f.endswith('.csv')]\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(split_dir, csv_file))\n",
    "    label_col = 'PHQ8_Binary' if 'PHQ8_Binary' in df.columns else ('PHQ_Binary' if 'PHQ_Binary' in df.columns else None)\n",
    "    if not label_col:\n",
    "        continue\n",
    "    seg_counts = [0, 0]  # [class0, class1]\n",
    "    for _, row in df.iterrows():\n",
    "        pid = int(row['Participant_ID'])\n",
    "        label = int(row[label_col])\n",
    "        part_dir = os.path.join(split_dir, f\"{pid}_P\")\n",
    "        if os.path.isdir(part_dir):\n",
    "            n_segments = len([f for f in os.listdir(part_dir) if f.endswith('.wav') and '_part' in f])\n",
    "            seg_counts[label] += n_segments\n",
    "    total = sum(seg_counts)\n",
    "    if total > 0:\n",
    "        percentages = np.round(100 * np.array(seg_counts) / total, 2)\n",
    "        print(f\"{csv_file} - segmenti 10s: {seg_counts}, percentuali: {percentages} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
