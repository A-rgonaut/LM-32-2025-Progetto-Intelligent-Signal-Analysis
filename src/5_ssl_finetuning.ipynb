{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModel, AutoFeatureExtractor\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from utils import load_labels_from_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2074e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDepressionDataset(Dataset):\n",
    "    def __init__(self, audio_paths, labels, model_name, sample_rate=16_000, max_length_in_seconds=20):\n",
    "        self.audio_paths = audio_paths  \n",
    "        self.labels = labels            \n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(model_name, do_normalize=False)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.max_length_in_seconds = max_length_in_seconds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def _load_audio(self, audio_path):\n",
    "        audio, _ = librosa.load(audio_path, self.sample_rate)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = audio.mean(axis=0)\n",
    "        audio = audio / np.max(np.abs(audio))\n",
    "        audio = audio.squeeze()\n",
    "        audio = torch.tensor(audio, dtype=torch.float32)\n",
    "        return audio\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.audio_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        audio = self._load_audio(audio_path)\n",
    "\n",
    "        features = self.feature_extractor(\n",
    "            audio, \n",
    "            sampling_rate=self.sample_rate,\n",
    "            max_length=self.sample_rate * self. max_length_in_seconds,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "    \n",
    "        return {\n",
    "            'input_values': features.input_values[0],\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73290837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveStatisticsPooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of Attentive Statistics Pooling based on\n",
    "    \"Attentive Statistics Pooling for Deep Speaker Embedding\" (https://www.isca-archive.org/interspeech_2018/okabe18_interspeech.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, attention_dim=64):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, attention_dim)\n",
    "        # BatchNorm1d is applied on the channel dimension\n",
    "        self.bn = nn.BatchNorm1d(attention_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(attention_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        Args:\n",
    "            x: The input tensor of shape (batch_size, seq_len, input_dim).\n",
    "        Returns:\n",
    "            The output tensor of shape (batch_size, input_dim * 2).\n",
    "        \"\"\"\n",
    "        # (batch_size, seq_len, input_dim) -> (batch_size, seq_len, attention_dim)\n",
    "        x_attn = self.linear1(x)\n",
    "\n",
    "        # BatchNorm requires shape (batch_size, channels, seq_len), so we transpose\n",
    "        # (batch_size, seq_len, attention_dim) -> (batch_size, attention_dim, seq_len)\n",
    "        x_attn = x_attn.transpose(1, 2)\n",
    "        x_attn = self.bn(x_attn)\n",
    "        # Transpose back to the original dimension order\n",
    "        # (batch_size, attention_dim, seq_len) -> (batch_size, seq_len, attention_dim)\n",
    "        x_attn = x_attn.transpose(1, 2)\n",
    "\n",
    "        # Apply activation and final linear layer\n",
    "        x_attn = self.relu(x_attn)\n",
    "        # (batch_size, seq_len, attention_dim) -> (batch_size, seq_len, 1)\n",
    "        attention_scores = self.linear2(x_attn)\n",
    "\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "\n",
    "        # Equation (5): Weighted mean\n",
    "        # (batch_size, seq_len, 1) * (batch_size, seq_len, input_dim) -> (batch_size, input_dim)\n",
    "        mean = torch.sum(attention_weights * x, dim=1)\n",
    "\n",
    "        # Equation (6): Weighted standard deviation\n",
    "        # E[X^2] - (E[X])^2\n",
    "        # (batch_size, seq_len, 1) * (batch_size, seq_len, input_dim) -> (batch_size, input_dim)\n",
    "        variance = torch.sum(attention_weights * x.pow(2), dim=1) - mean.pow(2)\n",
    "        std_dev = torch.sqrt(variance.clamp(min=1e-6))\n",
    "\n",
    "        # (batch_size, input_dim), (batch_size, input_dim) -> (batch_size, input_dim * 2)\n",
    "        pooled_output = torch.cat((mean, std_dev), dim=1)\n",
    "\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89dacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepressionClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, dropout):\n",
    "        super(DepressionClassifier, self).__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.ssl_model = AutoModel.from_pretrained(self.model_name, output_hidden_states=True)\n",
    "        self.ssl_hidden_size = self.ssl_model.config.hidden_size\n",
    "        self.head_hidden_size = self.ssl_hidden_size\n",
    "        \n",
    "        # TODO aggiungere codice per freezare layer se serve\n",
    "        \n",
    "        print(f'Number of trainable parameters: {sum(p.numel() for p in self.ssl_model.parameters() if p.requires_grad) / 1e6:.2f}M')\n",
    "        \n",
    "        # +1 perchÃ¨ prendiamo anche il layer che fa feature extraction\n",
    "        layers_to_aggregate = self.ssl_model.num_hidden_layers + 1\n",
    "        self.layer_weights = nn.Parameter(torch.ones(layers_to_aggregate))\n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(self.ssl_hidden_size) for _ in range(layers_to_aggregate)\n",
    "        ])\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        # dimensione tensore in input allo strato di pooling\n",
    "        self.pooling_embedding_dim = self.ssl_hidden_size\n",
    "        # dimensione tensore in output dallo strato di pooling\n",
    "        self.global_embedding_dim = self.ssl_hidden_size\n",
    "\n",
    "        self.pooling_layer = AttentiveStatisticsPooling(input_dim=self.pooling_embedding_dim)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.global_embedding_dim, self.head_hidden_size),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.head_hidden_size, self.num_classes),\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # initialize weights of classifier\n",
    "        for name, param in self.classifier.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_normal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ssl_input = batch['input_values']\n",
    "        \n",
    "        ssl_hidden_states = self.ssl_model(\n",
    "            input_values=ssl_input,\n",
    "            return_dict=True,\n",
    "        ).hidden_states\n",
    "\n",
    "        ssl_hidden_state = torch.zeros_like(ssl_hidden_states[-1])\n",
    "        weights = self.softmax(self.layer_weights)\n",
    "        for i in range(self.ssl_model.config.num_hidden_layers + 1):\n",
    "            ssl_hidden_state += weights[i] * self.layer_norms[i](ssl_hidden_states[i])\n",
    "        \n",
    "        # attention pooling\n",
    "        features = self.pooling_layer(ssl_hidden_state)\n",
    "\n",
    "        output = self.classifier(features)\n",
    "\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
